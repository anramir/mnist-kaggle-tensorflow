{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Input pipeline functions\n",
    "Functions needed for processing train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_csv_columns(file):\n",
    "    \n",
    "    with open(file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        columns = next(reader)\n",
    "        \n",
    "    return columns\n",
    "\n",
    "def create_array_types(file, type):\n",
    "    return [type for c in get_csv_columns(file)]\n",
    "\n",
    "train_record_defaults = create_array_types('train.csv', [1])\n",
    "test_record_defaults = create_array_types('test.csv', [1])\n",
    "\n",
    "\n",
    "def get_train_record(record):\n",
    "    vector = tf.decode_csv(record, train_record_defaults)\n",
    "    return vector[1:], vector[0]\n",
    "\n",
    "def get_test_record(record):\n",
    "    return tf.decode_csv(record, test_record_defaults)\n",
    "\n",
    "def reshape_train_image(feature, label):\n",
    "    return tf.reshape(feature, [28, 28, 1]), label\n",
    "\n",
    "def reshape_test_image(feature):\n",
    "    return tf.reshape(feature, [28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    filenames = ['train.csv']\n",
    "\n",
    "    dataset = tf.contrib.data.Dataset.from_tensor_slices(filenames)\n",
    "    dataset = dataset \\\n",
    "                .flat_map(lambda filename: (tf.contrib.data.TextLineDataset(filename).skip(1))) \\\n",
    "                .map(get_train_record) \\\n",
    "                .map(reshape_train_image) \\\n",
    "                .shuffle(buffer_size=10000)\n",
    "\n",
    "    batch = dataset.batch(256)\n",
    "\n",
    "    iterator = batch.make_one_shot_iterator()\n",
    "    features, labels = iterator.get_next()\n",
    "    return features, tf.one_hot(tf.cast(labels, tf.int32), 10)\n",
    "\n",
    "def test_input_fn():\n",
    "    filenames = ['test.csv']\n",
    "\n",
    "    dataset = tf.contrib.data.Dataset.from_tensor_slices(filenames)\n",
    "    dataset = dataset \\\n",
    "                .flat_map(lambda filename: (tf.contrib.data.TextLineDataset(filename).skip(1))) \\\n",
    "                .map(get_test_record) \\\n",
    "                .map(reshape_test_image) \\\n",
    "\n",
    "    batch = dataset.batch(256)\n",
    "\n",
    "    iterator = batch.make_one_shot_iterator()\n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Creating Convolutional 2D Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "\n",
    "    float_features = tf.cast(features, tf.float32)\n",
    "    normalized_features = tf.layers.batch_normalization(float_features)\n",
    "    \n",
    "    conv1 = tf.layers.conv2d( \\\n",
    "                inputs=normalized_features, \\\n",
    "                filters=32, \\\n",
    "                kernel_size=[5, 5], \\\n",
    "                padding=\"same\", \\\n",
    "                activation=tf.nn.relu \\\n",
    "            )\n",
    "\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d( \\\n",
    "                inputs=pool1, \\\n",
    "                filters=64, \\\n",
    "                kernel_size=[5, 5], \\\n",
    "                padding=\"same\", \\\n",
    "                activation=tf.nn.relu \\\n",
    "            )\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "    \n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "    \n",
    "    predictions = {\n",
    "        'classes': tf.argmax(input=logits, axis = 1),\n",
    "        'probabilities' : tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    ## PREDICT MODE\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    ## FOR TRAINING AND EVALUATION MODE\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)\n",
    "    \n",
    "    \n",
    "    ## TRAIN MODE\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    ## EVAL MODE\n",
    "    eval_metric_ops = {\n",
    "        'accuracy': tf.metrics.accuracy(labels=tf.argmax(labels, axis = 1), predictions=predictions[\"classes\"])\n",
    "    }\n",
    "    return  tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Second convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_model_dir': '/tmp/mnist_cnvnet_model', '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_tf_random_seed': 1, '_session_config': None}\n"
     ]
    }
   ],
   "source": [
    "mnist_classifier = tf.estimator.Estimator(model_fn = cnn_model_fn, model_dir='/tmp/mnist_cnvnet_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_cnvnet_model\\model.ckpt-2146\n",
      "INFO:tensorflow:Saving checkpoints for 2147 into /tmp/mnist_cnvnet_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0752455, step = 2147\n",
      "INFO:tensorflow:global_step/sec: 4.59191\n",
      "INFO:tensorflow:loss = 0.0722309, step = 2247 (21.777 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2311 into /tmp/mnist_cnvnet_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0255472.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x15f1da85eb8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_classifier.train( \\\n",
    "    input_fn=train_input_fn, \\\n",
    "    steps=200000, \\\n",
    "    hooks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-08-30-22:23:05\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_cnvnet_model\\model.ckpt-2311\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-30-22:23:33\n",
      "INFO:tensorflow:Saving dict for global step 2311: accuracy = 0.978071, global_step = 2311, loss = 0.0722973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.97807145, 'global_step': 2311, 'loss': 0.07229735}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_classifier.evaluate(input_fn=train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_predictions(predictions, batch):\n",
    "    with open('output.csv', 'a') as f:\n",
    "        for i, p in enumerate(predictions):\n",
    "            f.write('%s,%s\\n' % (batch* i + 1, p['classes']))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_cnvnet_model\\model.ckpt-2146\n"
     ]
    }
   ],
   "source": [
    "with open('output.csv', 'w') as f:\n",
    "    f.write('ImageId,Label\\n')\n",
    "    f.close()\n",
    "    \n",
    "for batch in range(300):\n",
    "    predictions = mnist_classifier.predict(input_fn=test_input_fn)\n",
    "    while True:\n",
    "        try:\n",
    "            print_predictions(predictions, batch+1)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
